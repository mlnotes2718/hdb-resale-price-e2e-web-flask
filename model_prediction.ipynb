{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb5cda1",
   "metadata": {},
   "source": [
    "# Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "985e8526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from joblib import load\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, root_mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489a7a1b",
   "metadata": {},
   "source": [
    "## Download Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "770fd197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to download file from: https://raw.githubusercontent.com/mlnotes2718/hdb-resale-price-e2e-ml/main/hdb_resale_best_model.joblib\n",
      "File successfully downloaded to: model/hdb_resale_best_model.joblib\n"
     ]
    }
   ],
   "source": [
    "def download_github_file(raw_url: str, save_path: str):\n",
    "    \"\"\"\n",
    "    Downloads a file from a GitHub raw content URL and saves it to a specified path.\n",
    "\n",
    "    Args:\n",
    "        raw_url (str): The raw URL of the file on GitHub (e.g.,\n",
    "                       'https://raw.githubusercontent.com/user/repo/branch/path/to/file').\n",
    "        save_path (str): The local path where the downloaded file will be saved.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to download file from: {raw_url}\")\n",
    "    try:\n",
    "        response = requests.get(raw_url, stream=True)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
    "\n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "        with open(save_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"File successfully downloaded to: {save_path}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading the file: {e}\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error saving the file to disk: {e}\")\n",
    "\n",
    "# Example usage with your provided URL:\n",
    "# Note: The URL you provided (https://github.com/mlnotes2718/hdb-resale-price-e2e-ml/blob/main/hdb_resale_best_model.joblib)\n",
    "# is for the GitHub web page. For raw content, you need to use the 'raw.githubusercontent.com' domain.\n",
    "# The correct raw URL for your file would be:\n",
    "# https://raw.githubusercontent.com/mlnotes2718/hdb-resale-price-e2e-ml/main/hdb_resale_best_model.joblib\n",
    "\n",
    "# Define the raw URL\n",
    "github_raw_url = \"https://raw.githubusercontent.com/mlnotes2718/hdb-resale-price-e2e-ml/main/hdb_resale_best_model.joblib\"\n",
    "\n",
    "# Define the local path to save the file\n",
    "local_save_path = \"model/hdb_resale_best_model.joblib\"\n",
    "\n",
    "# Call the function to download the file\n",
    "download_github_file(github_raw_url, local_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278c6f1c",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5e39231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path: str):\n",
    "    \"\"\"\n",
    "    Loads a machine learning model from a .joblib file.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): The local path to the .joblib model file.\n",
    "\n",
    "    Returns:\n",
    "        object: The loaded machine learning model or pipeline.\n",
    "    \"\"\"\n",
    "    print(f\"\\nAttempting to load model from: {model_path}\")\n",
    "    try:\n",
    "        model = joblib.load(model_path)\n",
    "        print(\"Model loaded successfully.\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84400238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to load model from: model/hdb_resale_best_model.joblib\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model(local_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e475a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, data: dict):\n",
    "    \"\"\"\n",
    "    Makes a prediction using the loaded model, checking feature names.\n",
    "\n",
    "    Args:\n",
    "        model: The loaded machine learning model or pipeline.\n",
    "        data (dict): A dictionary containing the input features for prediction.\n",
    "                     Keys should match the expected feature names of the model.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray or float: The prediction result.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        print(\"Model is not loaded. Cannot make prediction.\")\n",
    "        return None\n",
    "\n",
    "    print(\"\\nPreparing data for prediction...\")\n",
    "    # Convert the input data dictionary into a pandas DataFrame\n",
    "    # This is crucial as scikit-learn models often expect DataFrame inputs\n",
    "    input_df = pd.DataFrame([data])\n",
    "\n",
    "    # --- Feature Name and Pipeline Inspection ---\n",
    "    # This part demonstrates how to check feature names and pipeline steps.\n",
    "    # The exact method depends on the model type (e.g., Pipeline, specific estimator).\n",
    "\n",
    "    # If it's a scikit-learn Pipeline, you can inspect its steps\n",
    "    if hasattr(model, 'steps') and isinstance(model.steps, list):\n",
    "        print(\"\\nModel is a scikit-learn Pipeline. Steps:\")\n",
    "        for i, (name, step) in enumerate(model.steps):\n",
    "            print(f\"  Step {i+1}: {name} ({type(step).__name__})\")\n",
    "            # You might want to inspect feature names at different stages if applicable\n",
    "            # For example, if a step has get_feature_names_out()\n",
    "            if hasattr(step, 'get_feature_names_out'):\n",
    "                try:\n",
    "                    # This might require fitting the step first, or it might work\n",
    "                    # if the pipeline is already fitted.\n",
    "                    # For a fresh prediction, we're mostly concerned with the input features.\n",
    "                    pass\n",
    "                except Exception:\n",
    "                    pass # Ignore if it fails, not all steps have this readily available\n",
    "\n",
    "    # For checking expected input feature names (common for models trained with specific columns)\n",
    "    # This assumes the model was trained with a DataFrame and might have a feature_names_in_ attribute\n",
    "    if hasattr(model, 'feature_names_in_'):\n",
    "        expected_features = model.feature_names_in_\n",
    "        print(f\"\\nModel expects the following features: {list(expected_features)}\")\n",
    "        # Check if all expected features are present in the input data\n",
    "        missing_features = [f for f in expected_features if f not in input_df.columns]\n",
    "        if missing_features:\n",
    "            print(f\"WARNING: Missing features in input data: {missing_features}\")\n",
    "            # You might want to add default values or raise an error here\n",
    "            # For simplicity, we'll proceed but this is a common point of error.\n",
    "            # Add missing columns with NaN or appropriate default values\n",
    "            for feature in missing_features:\n",
    "                input_df[feature] = 0 # Or np.nan, or a sensible default for your model\n",
    "\n",
    "    # Ensure the order of columns in input_df matches the expected order if feature_names_in_ exists\n",
    "    if hasattr(model, 'feature_names_in_'):\n",
    "        input_df = input_df[list(model.feature_names_in_)]\n",
    "    else:\n",
    "        print(\"Warning: Model does not expose 'feature_names_in_'. Ensure input data column order matches training data.\")\n",
    "\n",
    "\n",
    "    print(f\"Input data for prediction:\\n{input_df}\")\n",
    "\n",
    "    try:\n",
    "        prediction = model.predict(input_df)\n",
    "        print(f\"Prediction successful. Result: {prediction}\")\n",
    "        return prediction\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a42f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_model_features(model):\n",
    "    \"\"\"\n",
    "    Examines and prints the feature names expected by the loaded model.\n",
    "\n",
    "    Args:\n",
    "        model: The loaded machine learning model or pipeline.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        print(\"Model is not loaded. Cannot examine features.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Examining Model Features ---\")\n",
    "    if hasattr(model, 'feature_names_in_'):\n",
    "        print(f\"Model expects the following input features: {list(model.feature_names_in_)}\")\n",
    "    elif hasattr(model, 'steps') and isinstance(model.steps, list):\n",
    "        print(\"Model is a scikit-learn Pipeline. Attempting to find features from the first estimator.\")\n",
    "        # Try to get features from the first estimator in the pipeline if available\n",
    "        for name, step in model.steps:\n",
    "            if hasattr(step, 'feature_names_in_'):\n",
    "                print(f\"First step '{name}' expects the following input features: {list(step.feature_names_in_)}\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"Could not directly determine expected features from the pipeline steps using 'feature_names_in_'.\")\n",
    "            print(\"You might need to refer to the model's training script or documentation.\")\n",
    "    else:\n",
    "        print(\"Could not directly determine expected features. Model does not expose 'feature_names_in_'.\")\n",
    "        print(\"You might need to refer to the model's training script or documentation.\")\n",
    "    print(\"--- End Feature Examination ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3685e176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Examining Model Features ---\n",
      "Model expects the following input features: ['town', 'flat_type', 'storey_range', 'floor_area_sqm', 'flat_model', 'transac_year', 'transac_month', 'remaining_lease_by_months']\n",
      "--- End Feature Examination ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examine_model_features(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3425d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of more realistic dummy data based on common HDB features:\n",
    "# You'll need to adjust these based on the actual features used by 'hdb_resale_best_model.joblib'\n",
    "# To find the exact features, you might need to inspect the model after loading,\n",
    "# or refer to the repository's data preparation steps.\n",
    "example_hdb_data = {\n",
    "    'town': 'ANG MO KIO', # list of towns in Singapore\n",
    "    'flat_type': '4 ROOM', # list of flat types in Singapore\n",
    "    'storey_range': 10,\n",
    "    'floor_area_sqm': 90.0,\n",
    "    'flat_model': 'New Generation', # list of flat models in Singapore\n",
    "    'transac_year': 2025,\n",
    "    'transac_month': 7,\n",
    "    'remaining_lease_by_months': 600 # Example: 50 years * 12 months, ask user more than or less than between 10 to 90, 95\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "955e6e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing data for prediction...\n",
      "\n",
      "Model is a scikit-learn Pipeline. Steps:\n",
      "  Step 1: preprocessor (ColumnTransformer)\n",
      "  Step 2: regressor (LinearRegression)\n",
      "\n",
      "Model expects the following features: ['town', 'flat_type', 'storey_range', 'floor_area_sqm', 'flat_model', 'transac_year', 'transac_month', 'remaining_lease_by_months']\n",
      "Input data for prediction:\n",
      "         town flat_type  storey_range  floor_area_sqm      flat_model  \\\n",
      "0  ANG MO KIO    4 ROOM            10            90.0  New Generation   \n",
      "\n",
      "   transac_year  transac_month  remaining_lease_by_months  \n",
      "0          2025              7                        600  \n",
      "Prediction successful. Result: [550418.88179136]\n",
      "\n",
      "Final Predicted Resale Price: 550,418.88\n"
     ]
    }
   ],
   "source": [
    "# 4. Make a prediction using the loaded model and dummy data\n",
    "if loaded_model:\n",
    "    # Use the more realistic example data\n",
    "    prediction_result = make_prediction(loaded_model, example_hdb_data)\n",
    "    if prediction_result is not None:\n",
    "        print(f\"\\nFinal Predicted Resale Price: {prediction_result[0]:,.2f}\")\n",
    "    else:\n",
    "        print(\"\\nPrediction could not be made.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e225b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdbflask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
